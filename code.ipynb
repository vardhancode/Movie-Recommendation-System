{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9383\n",
      "\n",
      "âœ… Model training complete!\n",
      "Test RMSE: 0.9383\n",
      "\n",
      "ðŸŽ¬ Top 5 Recommendations for User 196:\n",
      "Movie ID 169 | Predicted Rating: 4.51\n",
      "Movie ID 408 | Predicted Rating: 4.49\n",
      "Movie ID 511 | Predicted Rating: 4.48\n",
      "Movie ID 197 | Predicted Rating: 4.47\n",
      "Movie ID 513 | Predicted Rating: 4.44\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Path to your dataset\n",
    "\n",
    "file_path = r\"C:/Movie Rec System/ml-100k/u.data\"  \n",
    "\n",
    "\n",
    "# Step 2: Load dataset into Surprise\n",
    "\n",
    "reader = Reader(line_format=\"user item rating timestamp\", sep=\"\\t\")\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "\n",
    "# Step 3: Train/Test split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "\n",
    "# Step 4: Build & train model\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "\n",
    "# Step 5: Evaluate model\n",
    "\n",
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "\n",
    "print(\"\\n Model training complete!\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# Step 6: Make Recommendations for one user\n",
    "\n",
    "def recommend_for_user(user_id, model, data, n=5):\n",
    "    # Get all items\n",
    "    trainset = model.trainset\n",
    "    all_items = trainset.all_items()\n",
    "    all_item_ids = [trainset.to_raw_iid(i) for i in all_items]\n",
    "\n",
    "    # Predict ratings for every item not seen by user\n",
    "    user_seen = set([j for (j, _) in trainset.ur[trainset.to_inner_uid(str(user_id))]])\n",
    "    predictions = [\n",
    "        (iid, model.predict(str(user_id), iid).est)\n",
    "        for iid in all_item_ids if trainset.to_inner_iid(iid) not in user_seen\n",
    "    ]\n",
    "\n",
    "    # Sort by predicted rating\n",
    "    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    return top_n\n",
    "\n",
    "# Example: Recommend for user 196\n",
    "user_id = 196\n",
    "recommendations = recommend_for_user(user_id, model, data, n=5)\n",
    "\n",
    "print(f\"\\nðŸŽ¬ Top 5 Recommendations for User {user_id}:\")\n",
    "for movie_id, score in recommendations:\n",
    "    print(f\"Movie ID {movie_id} | Predicted Rating: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6911dfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# path to your dataset\n",
    "file_path = r\"C:/Movie Rec System/ml-100k/u.data\"\n",
    "\n",
    "# Load with pandas (just to check structure)\n",
    "columns = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", names=columns)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62feb324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieLens data loaded into Surprise!\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Path to your dataset\n",
    "file_path = r\"C:/Movie Rec System/ml-100k/u.data\"\n",
    "\n",
    "# Define the format of the file (order of columns, separator, rating scale)\n",
    "reader = Reader(line_format=\"user item rating timestamp\", sep=\"\\t\", rating_scale=(1, 5))\n",
    "\n",
    "# Load the dataset\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "print(\"MovieLens data loaded into Surprise!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c964c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset and testset ready!\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "print(\"Trainset and testset ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72760f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9773\n",
      "RMSE: 0.9773056480824995\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import accuracy\n",
    "\n",
    "# Using KNN collaborative filtering\n",
    "algo = KNNBasic()\n",
    "\n",
    "# Train the model on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Test the model on the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Check performance\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e05443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 1\n",
      "MovieID: 302, Predicted Rating: 3.53\n",
      "MovieID: 377, Predicted Rating: 3.53\n",
      "MovieID: 346, Predicted Rating: 3.53\n",
      "MovieID: 474, Predicted Rating: 3.53\n",
      "MovieID: 465, Predicted Rating: 3.53\n"
     ]
    }
   ],
   "source": [
    "# Pick a user\n",
    "user_id = str(1)  \n",
    "\n",
    "# Get all movie IDs\n",
    "all_movie_ids = df[\"movie_id\"].unique()\n",
    "\n",
    "# Get movies the user has already rated\n",
    "rated_movies = df[df[\"user_id\"] == int(user_id)][\"movie_id\"].tolist()\n",
    "\n",
    "# Recommend only the ones not rated\n",
    "unrated_movies = [m for m in all_movie_ids if m not in rated_movies]\n",
    "\n",
    "# Predict ratings for these unrated movies\n",
    "predictions = [algo.predict(user_id, m) for m in unrated_movies]\n",
    "\n",
    "# Sort by predicted rating\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Top 5 recommendations\n",
    "top5 = predictions[:5]\n",
    "\n",
    "print(\"Top 5 recommendations for user\", user_id)\n",
    "for p in top5:\n",
    "    print(f\"MovieID: {p.iid}, Predicted Rating: {p.est:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b289e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movie metadata (u.item has | separator)\n",
    "movies = pd.read_csv(\n",
    "    r\"C:\\Movie Rec System/ml-100k/u.item\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    encoding=\"latin-1\",\n",
    "    usecols=[0, 1],  # movie_id, title\n",
    "    names=[\"movie_id\", \"title\"]\n",
    ")\n",
    "\n",
    "# Convert to dictionary {movie_id: title}\n",
    "movie_dict = dict(zip(movies[\"movie_id\"], movies[\"title\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bc2875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 1\n",
      "L.A. Confidential (1997) (Predicted Rating: 3.53)\n",
      "Heavyweights (1994) (Predicted Rating: 3.53)\n",
      "Jackie Brown (1997) (Predicted Rating: 3.53)\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) (Predicted Rating: 3.53)\n",
      "Jungle Book, The (1994) (Predicted Rating: 3.53)\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 recommendations for user\", user_id)\n",
    "for p in top5:\n",
    "    movie_name = movie_dict.get(int(p.iid), \"Unknown Movie\")\n",
    "    print(f\"{movie_name} (Predicted Rating: {p.est:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f16b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_6724\\3480201738.py:9: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  \"C:\\Movie Rec System/ml-100k/u.item\",\n"
     ]
    }
   ],
   "source": [
    "# u.item has many columns, genres are in last 19 (0/1 for each genre)\n",
    "genre_cols = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "movies_full = pd.read_csv(\n",
    "    \"C:\\Movie Rec System/ml-100k/u.item\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    encoding=\"latin-1\"\n",
    ")\n",
    "\n",
    "# Extract only movie_id, title + genres\n",
    "movies_with_genres = movies_full.iloc[:, [0,1] + list(range(5, 24))]\n",
    "movies_with_genres.columns = [\"movie_id\", \"title\"] + genre_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc6373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Just take the genre vectors\n",
    "genre_features = movies_with_genres[genre_cols].values\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(genre_features, genre_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa361182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_genre(movie_title, top_n=5):\n",
    "    # Find the index of the movie\n",
    "    idx = movies_with_genres[movies_with_genres[\"title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top_n similar movies (skip the first one because it's the same movie)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    \n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies_with_genres.iloc[movie_indices][[\"title\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hybrid_recommend(user_id, movie_title, top_n=5, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Hybrid recommender that combines collaborative filtering and content-based filtering.\n",
    "    \n",
    "    user_id: the ID of the user weâ€™re recommending for\n",
    "    movie_title: a movie the user already liked (for content similarity)\n",
    "    top_n: number of recommendations\n",
    "    alpha: weight for collaborative filtering (0.0â€“1.0)\n",
    "           (alpha closer to 1 â†’ CF dominates, closer to 0 â†’ CBF dominates)\n",
    "    \"\"\"\n",
    "    \n",
    "    #  Content-based part \n",
    "    idx = movies_with_genres[movies_with_genres[\"title\"] == movie_title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:50]   # take top 50 similar movies\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    cbf_movies = movies_with_genres.iloc[movie_indices][[\"movie_id\", \"title\"]]\n",
    "    cbf_scores = np.array([s[1] for s in sim_scores])\n",
    "    \n",
    "    #  Collaborative part \n",
    "    cf_scores = []\n",
    "    for mid in cbf_movies[\"movie_id\"]:\n",
    "        try:\n",
    "            pred = algo.predict(user_id, mid).est\n",
    "        except:\n",
    "            pred = 0\n",
    "        cf_scores.append(pred)\n",
    "    cf_scores = np.array(cf_scores)\n",
    "    \n",
    "    #  Combine \n",
    "    final_scores = alpha * cf_scores + (1 - alpha) * cbf_scores\n",
    "    \n",
    "    # Get top_n results\n",
    "    cbf_movies[\"score\"] = final_scores\n",
    "    cbf_movies = cbf_movies.sort_values(\"score\", ascending=False)\n",
    "    \n",
    "    return cbf_movies.head(top_n)[[\"title\", \"score\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smile-env)",
   "language": "python",
   "name": "smile_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
